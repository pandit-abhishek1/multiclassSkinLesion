# -*- coding: utf-8 -*-
"""ibr.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10uuzHEatXZwZL0o7qAvEnn3q8KJqY_tE
"""

import torch
import torch.nn as nn
from torchvision.models import mobilenet_v2, MobileNet_V2_Weights

mobilenet_v2().features

class IBR5Net_MobileNetV2(nn.Module):
    def __init__(self, num_classes=7, pretrained=True):
        super().__init__()

        weights = MobileNet_V2_Weights.IMAGENET1K_V1 if pretrained else None
        base_model = mobilenet_v2(weights=weights)

        # -----------------------------
        # Take ONLY first 5 blocks
        # -----------------------------
        self.features = nn.Sequential(
            *list(base_model.features.children())[:5]
        )

        # Output channels after block 5 = 32
        self.conv_expand = nn.Sequential(
            nn.Conv2d(32, 512, kernel_size=1, bias=False),
            nn.BatchNorm2d(512),
            nn.ReLU6(inplace=True)
        )

        self.pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Linear(512, num_classes)

    def forward(self, x):
        x = self.features(x)
        x = self.conv_expand(x)
        x = self.pool(x)
        x = x.flatten(1)
        return x

model = IBR5Net_MobileNetV2(num_classes=7)
x = torch.randn(1, 3, 224, 224)
y = model(x)

print(y.shape)  # torch.Size([1, 512])

class IBR6Net_MobileNetV2(nn.Module):
    def __init__(self, num_classes=7, pretrained=True):
        super().__init__()

        weights = MobileNet_V2_Weights.IMAGENET1K_V1 if pretrained else None
        base_model = mobilenet_v2(weights=weights)

        # Use first 11 blocks. The output channels from the 11th block is 64.
        self.features = nn.Sequential(
            *list(base_model.features.children())[:11]
        )

        # Corrected: Input channels changed from 96 to 64 to match the output of self.features
        self.conv_expand = nn.Sequential(
            nn.Conv2d(64, 1024, kernel_size=1, bias=False),
            nn.BatchNorm2d(1024),
            nn.ReLU6(inplace=True)
        )

        self.pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Linear(1024, num_classes)

    def forward(self, x):
        x = self.features(x)
        x = self.conv_expand(x)
        x = self.pool(x)
        x = x.flatten(1)
        return x

model = IBR6Net_MobileNetV2(num_classes=7)
x = torch.randn(1, 3, 224, 224)
y = model(x)

print(y.shape)

import torch
import torch.nn as nn


class Fused_IBR5_IBR6(nn.Module):
    def __init__(self, num_classes=7, pretrained=True):
        super().__init__()

        # Backbone networks
        self.ibr5 = IBR5Net_MobileNetV2(
            num_classes=num_classes,
            pretrained=pretrained
        )

        self.ibr6 = IBR6Net_MobileNetV2(
            num_classes=num_classes,
            pretrained=pretrained
        )

        # -----------------------------
        # Fusion classifier (shallow NN)
        # -----------------------------
        self.classifier = nn.Sequential(
            nn.Linear(512 + 1024, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(512, num_classes)
        )

    def forward(self, x):
        # Extract features
        f5 = self.ibr5(x)   # [B, 512]
        f6 = self.ibr6(x)   # [B, 1024]

        # Network-level fusion (depth concat)
        fused = torch.cat((f5, f6), dim=1)  # [B, 1536]

        # Classification
        out = self.classifier(fused)
        return out

model = Fused_IBR5_IBR6(num_classes=7)
x = torch.randn(1, 3, 224, 224)
y = model(x)

print(y.shape)